{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               157000    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159,010\n",
      "Trainable params: 159,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3000 - accuracy: 0.9162 - val_loss: 0.1727 - val_accuracy: 0.9489\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1351 - accuracy: 0.9597 - val_loss: 0.1119 - val_accuracy: 0.9674\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0940 - accuracy: 0.9721 - val_loss: 0.1030 - val_accuracy: 0.9684\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0716 - accuracy: 0.9790 - val_loss: 0.0877 - val_accuracy: 0.9732\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0568 - accuracy: 0.9835 - val_loss: 0.0757 - val_accuracy: 0.9763\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0466 - accuracy: 0.9865 - val_loss: 0.0900 - val_accuracy: 0.9725\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.0740 - val_accuracy: 0.9756\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0323 - accuracy: 0.9910 - val_loss: 0.0712 - val_accuracy: 0.9796\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0270 - accuracy: 0.9921 - val_loss: 0.0761 - val_accuracy: 0.9769\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0227 - accuracy: 0.9937 - val_loss: 0.0774 - val_accuracy: 0.9766\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "# read\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# x_train = N x row x col\n",
    "img_rows = x_train.shape[1] # 28\n",
    "img_cols = x_train.shape[2] # 28\n",
    "\n",
    "batch_size = 128 # mini-batch의 크기, 전체 batch 크기는 6만개 \n",
    "num_classes = 10 # class의 개수\n",
    "epochs = 10 # epoch을 몇번 돌건지\n",
    "\n",
    "# preprocess\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols)\n",
    "\n",
    "# 0에서 1사이 실수로 바꿔줌\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# onehot coding 으로 바꿈\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# MLP model\n",
    "model = Sequential() \n",
    "#Flatten 은 행렬을 벡터로 만들어줌\n",
    "model.add(Flatten(input_shape = (img_rows,img_cols))) # 2D image -> 1D vector\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "model.summary()\n",
    "\n",
    "# learning, verbose는 매번 출력하는것\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs,\n",
    "                 verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 77ms/step\n",
      "The Answer is  [9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = np.random.randint(0,10000,1)\n",
    "\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(x_test[n].reshape(28, 28), cmap = 'gray')\n",
    "\n",
    "print('The Answer is ', np.argmax(model.predict(x_test[n]), axis = -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 4, 7, 20)          340       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 1, 2, 50)          16050     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,500\n",
      "Trainable params: 27,500\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5537 - accuracy: 0.8401 - val_loss: 0.2541 - val_accuracy: 0.9236\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2273 - accuracy: 0.9302 - val_loss: 0.1716 - val_accuracy: 0.9488\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1681 - accuracy: 0.9474 - val_loss: 0.1428 - val_accuracy: 0.9543\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1391 - accuracy: 0.9558 - val_loss: 0.1314 - val_accuracy: 0.9588\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1205 - accuracy: 0.9614 - val_loss: 0.1182 - val_accuracy: 0.9611\n"
     ]
    }
   ],
   "source": [
    "# read\n",
    "batch_size = 128 # mini-batch의 크기\n",
    "num_classes = 10 # class의 개수\n",
    "epochs = 5 # epoch을 몇번 돌건지\n",
    "\n",
    "# preprocess, 흑백이라서 channel = 1 \n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# CNN model, conv2D는 2차원 컨볼류션 layer / 20의 의미는 kernel 20개 쓴다. \n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size = (4, 4), strides = (7, 4), padding = 'same', activation = 'relu',input_shape=input_shape))\n",
    "model.add(Conv2D(50, kernel_size = (4, 4), strides = (4, 4), padding = 'same', activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(num_classes, activation = 'softmax'))\n",
    "model.summary()\n",
    "# parameter 340인 이유 : {(4,4)kernel + bias 파라미터 1개} x 20\n",
    "# parameter 16050인 이유 : 20*50*16 + 50\n",
    "# output shape 은 한 그림에서 나오는 개수 의미 = channel\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs,\n",
    "                 verbose = 1, validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.randint(0,10000,1)\n",
    "\n",
    "plt.figure(figsize = (4,4))\n",
    "plt.imshow(x_test[n].reshape(28, 28), cmap = 'gray')\n",
    "\n",
    "print('The Answer is ', np.argmax(model.predict(x_test[n]), axis = -1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
